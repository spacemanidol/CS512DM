\documentclass[11pt]{article}

\usepackage{alltt,fullpage,graphics,color,epsfig,amsmath, amssymb}
\usepackage{hyperref}
\usepackage{boxedminipage}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{amsmath}
\usepackage{commath}
\usepackage{graphicx}
\graphicspath{ {.} }
\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\ceil}[1]{\lceil #1 \rceil}

\title{CS 512 Assignment 2}
\author{Daniel Campos}
\date{April 25th,2021}
\begin{document}
\maketitle
\section{Problem 1}
\subsection{Short Answers}
\subsubsection{What is overfitting? What are two techniques that can mitigate this issue and explain why they handle overfitting.}
\subsubsection{Compare LSTM and GRU, what do they have in common and what are their differences}
\subsection{Back Propagation}
\subsubsection{Prove the error equation for unit $U_6$ and the weight update function for the same neuron}
\subsection{2D Convolution}
\subsubsection{Compute the feature maps by applying kernel $K_1$, $K_2$ (stride = 1)}
\subsubsection{Compute the new feature map after we apply average pooling with 2x2 filter from previous work}
\subsection{Graph Convolutional Networks}
\subsubsection{Is this task inductive learning or transductive learning
This is inductive learning because we only see a portion of the dataset while training (the train portion: 60\%) and then we apply the learned model on dataset it has never seen before (validation/eval data portions)
The main difference is that during transductive learning, you have already encountered both the training and testing datasets when training the model. However, inductive learning encounters only the training data when training the model and applies the learned model on a dataset which it has never seen before}
\subsubsection{Implement this model and evaluate and report accuracy}
Accuracy is X
\subsection{Vary the optimizer and learning rate strategies and report numbers}
I changed X and the effect was Z
\subsubsection{If the number of GCN layers increase how does the model performance change in terms of quality and efficiency}
If we increase the layers of the model we can model more complex data but do so with a computational overhead. In other words, a deeper network (more layers) is more computationally expensive to run and has a greater ability to fit the data. A deeper network can produce better accuracy but can also more easily overfit to the training data
\section{Outlier Detection}
\subsection{Short Answers}
\subsubsection{From the perspectives of outlier detection methods give two possible definitions of outliers}
\subsection{What is the disadvantage of describing outliers as any point that is larger than the majority of values? How do we modify our definition of outliers to avoid this problem? Use examples }
\subsection{Implementation using $PyOD^3$}
Run 3 methods where at least 1 is neural network based on each of the datasets and evaluate performance using Precision/Recall @ k where K=10, 20, 50.
Create ROC curves for the various metrics. 
\section{Gaussian Mixture Model}
\subsection{Compared with K-Means, what are the advantages and disadvantages of Gaussian mixute model}

\end{document}